{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative to Python for Finance, Part 1\n",
    "\n",
    "[Here](http://www.learndatasci.com/python-finance-part-yahoo-finance-api-pandas-matplotlib/) is the original website. The original text is copied from the source.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Data\n",
    "\n",
    "Pandas is included in the more popular distributions of Python for Windows, such as Anaconda. In case it's not included in your Python distribution, use pip: `pip install pandas`. Once installed, to use pandas, all one needs to do is import it. We will also need the `pandas_datareader` package (`pip install pandas-datareader`), as well as `matplotlib` (`pip install matplotlib`) for visualizing our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import relevant modules\n",
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having imported the appropriate tools, getting market data from a free online source, such as Yahoo Finance, is super easy. Since pandas has a simple remote data access for the Yahoo Finance API data, this is as simple as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the instruments to download. We would like to see Apple, Microsoft and the S&P500 index.\n",
    "tickers = ['AAPL', 'MSFT', 'SP']\n",
    "\n",
    "# We would like all available data from 01/01/2000 until today.\n",
    "today = time.strftime(\"%Y-%m-%d\")\n",
    "start_date = '2000-01-01'\n",
    "\n",
    "# User pandas_reader.data.DataReader to load the desired data. As simple as that.\n",
    "panel_data = data.DataReader(tickers, \"google\", start_date, today)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does `panel_data` look like? `data.DataReader` returns a Panel object, which can be thought of as a 3D matrix. The first dimension consists of the various fields Yahoo Finance returns for a given instrument, namely, the *Open, High, Low, Close* and *Adj Close* prices for each date. The second dimension contain the dates. The third one contains the instrument identifiers.\n",
    "\n",
    "Let's see what `panel_data` actually is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.core.panel.Panel'>\n",
       "Dimensions: 5 (items) x 4000 (major_axis) x 3 (minor_axis)\n",
       "Items axis: Open to Volume\n",
       "Major_axis axis: 2001-07-02 00:00:00 to 2017-05-26 00:00:00\n",
       "Minor_axis axis: AAPL to SP"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "\n",
    "Let us assume we are interested in working with the *Adj Close* prices which have been already been adjusted by Yahoo finance to account for corporate actions such as dividends and stock splits. We want to make sure that all weekdays are included in our dataset, which is very often desirable for quantitative trading strategies. Of course, some of the weekdays might be public holidays in which case no price will be available. For this reason, we will fill the missing prices with the latest available prices. All this is, again, all too easy with pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting just the adjusted closing prices. This will return a Pandas DataFrame\n",
    "# The index in this DataFrame is the major index of the panel_data.\n",
    "adj_close = panel_data.ix['Close']\n",
    "\n",
    "# Getting all weekdays between 01/01/2000 and today\n",
    "all_weekdays = pd.date_range(start=start_date, end=today, freq='B')\n",
    "\n",
    "# How do we align the existing prices in adj_close with our new set of dates?\n",
    "# All we need to do is reindex adj_close using all_weekdays as the new index\n",
    "adj_close = adj_close.reindex(all_weekdays)\n",
    "\n",
    "# Reindexing will insert missing values (NaN) for the dates that were not present\n",
    "# in the original set. To cope with this, we can fill the missing by replacing them\n",
    "# with the latest available price for each instrument.\n",
    "adj_close = adj_close.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, `adj_close` contains all the adjusted closing prices for all instruments and all the dates that Yahoo returned. Some of the week days might be missing from the data Yahoo provides. For this reason we create a Series of all the weekdays between the first and last date of interest and store them in the all_weekdays variable. Getting all the weekdays is achieved by passing the `freq=’B’` named parameter to the `pd.date_range()` function. This function return a `DatetimeIndex` which is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2000-01-03', '2000-01-04', '2000-01-05', '2000-01-06',\n",
       "               '2000-01-07', '2000-01-10', '2000-01-11', '2000-01-12',\n",
       "               '2000-01-13', '2000-01-14',\n",
       "               ...\n",
       "               '2017-05-15', '2017-05-16', '2017-05-17', '2017-05-18',\n",
       "               '2017-05-19', '2017-05-22', '2017-05-23', '2017-05-24',\n",
       "               '2017-05-25', '2017-05-26'],\n",
       "              dtype='datetime64[ns]', length=4540, freq='B')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_weekdays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aligning the original DataFrame with the new DatetimeIndex is accomplished by substitution of the initial DatetimeIndex of the `adj_close` DataFrame. If any of the new dates were not included in the original DatetimeIndex, the prices for that date will be filled with NaNs. For this reason, we will fill any resulting NaNs with the last available price. The final, clean DataFrame is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>SP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-14</th>\n",
       "      <td>141.05</td>\n",
       "      <td>64.95</td>\n",
       "      <td>32.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-17</th>\n",
       "      <td>141.83</td>\n",
       "      <td>65.48</td>\n",
       "      <td>32.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-18</th>\n",
       "      <td>141.20</td>\n",
       "      <td>65.39</td>\n",
       "      <td>32.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-19</th>\n",
       "      <td>140.68</td>\n",
       "      <td>65.04</td>\n",
       "      <td>33.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-20</th>\n",
       "      <td>142.44</td>\n",
       "      <td>65.50</td>\n",
       "      <td>33.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-21</th>\n",
       "      <td>142.27</td>\n",
       "      <td>66.40</td>\n",
       "      <td>32.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-24</th>\n",
       "      <td>143.64</td>\n",
       "      <td>67.53</td>\n",
       "      <td>33.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-25</th>\n",
       "      <td>144.53</td>\n",
       "      <td>67.92</td>\n",
       "      <td>33.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-26</th>\n",
       "      <td>143.68</td>\n",
       "      <td>67.83</td>\n",
       "      <td>35.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-27</th>\n",
       "      <td>143.79</td>\n",
       "      <td>68.27</td>\n",
       "      <td>35.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-28</th>\n",
       "      <td>143.65</td>\n",
       "      <td>68.46</td>\n",
       "      <td>34.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-01</th>\n",
       "      <td>146.58</td>\n",
       "      <td>69.41</td>\n",
       "      <td>34.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-02</th>\n",
       "      <td>147.51</td>\n",
       "      <td>69.30</td>\n",
       "      <td>34.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-03</th>\n",
       "      <td>147.06</td>\n",
       "      <td>69.08</td>\n",
       "      <td>32.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-04</th>\n",
       "      <td>146.53</td>\n",
       "      <td>68.81</td>\n",
       "      <td>32.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-05</th>\n",
       "      <td>148.96</td>\n",
       "      <td>69.00</td>\n",
       "      <td>31.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-08</th>\n",
       "      <td>153.01</td>\n",
       "      <td>68.94</td>\n",
       "      <td>31.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-09</th>\n",
       "      <td>153.99</td>\n",
       "      <td>69.04</td>\n",
       "      <td>31.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-10</th>\n",
       "      <td>153.26</td>\n",
       "      <td>69.31</td>\n",
       "      <td>31.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-11</th>\n",
       "      <td>153.95</td>\n",
       "      <td>68.46</td>\n",
       "      <td>29.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-12</th>\n",
       "      <td>156.10</td>\n",
       "      <td>68.38</td>\n",
       "      <td>29.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-15</th>\n",
       "      <td>155.70</td>\n",
       "      <td>68.43</td>\n",
       "      <td>29.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-16</th>\n",
       "      <td>155.47</td>\n",
       "      <td>69.41</td>\n",
       "      <td>29.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-17</th>\n",
       "      <td>150.25</td>\n",
       "      <td>67.48</td>\n",
       "      <td>28.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-18</th>\n",
       "      <td>152.54</td>\n",
       "      <td>67.71</td>\n",
       "      <td>28.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-19</th>\n",
       "      <td>153.06</td>\n",
       "      <td>67.69</td>\n",
       "      <td>28.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-22</th>\n",
       "      <td>153.99</td>\n",
       "      <td>68.45</td>\n",
       "      <td>29.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-23</th>\n",
       "      <td>153.80</td>\n",
       "      <td>68.68</td>\n",
       "      <td>29.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-24</th>\n",
       "      <td>153.34</td>\n",
       "      <td>68.77</td>\n",
       "      <td>29.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-25</th>\n",
       "      <td>153.87</td>\n",
       "      <td>69.62</td>\n",
       "      <td>29.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4539 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              AAPL   MSFT     SP\n",
       "2000-01-03     NaN    NaN    NaN\n",
       "2000-01-04     NaN    NaN    NaN\n",
       "2000-01-05     NaN    NaN    NaN\n",
       "2000-01-06     NaN    NaN    NaN\n",
       "2000-01-07     NaN    NaN    NaN\n",
       "2000-01-10     NaN    NaN    NaN\n",
       "2000-01-11     NaN    NaN    NaN\n",
       "2000-01-12     NaN    NaN    NaN\n",
       "2000-01-13     NaN    NaN    NaN\n",
       "2000-01-14     NaN    NaN    NaN\n",
       "2000-01-17     NaN    NaN    NaN\n",
       "2000-01-18     NaN    NaN    NaN\n",
       "2000-01-19     NaN    NaN    NaN\n",
       "2000-01-20     NaN    NaN    NaN\n",
       "2000-01-21     NaN    NaN    NaN\n",
       "2000-01-24     NaN    NaN    NaN\n",
       "2000-01-25     NaN    NaN    NaN\n",
       "2000-01-26     NaN    NaN    NaN\n",
       "2000-01-27     NaN    NaN    NaN\n",
       "2000-01-28     NaN    NaN    NaN\n",
       "2000-01-31     NaN    NaN    NaN\n",
       "2000-02-01     NaN    NaN    NaN\n",
       "2000-02-02     NaN    NaN    NaN\n",
       "2000-02-03     NaN    NaN    NaN\n",
       "2000-02-04     NaN    NaN    NaN\n",
       "2000-02-07     NaN    NaN    NaN\n",
       "2000-02-08     NaN    NaN    NaN\n",
       "2000-02-09     NaN    NaN    NaN\n",
       "2000-02-10     NaN    NaN    NaN\n",
       "2000-02-11     NaN    NaN    NaN\n",
       "...            ...    ...    ...\n",
       "2017-04-14  141.05  64.95  32.40\n",
       "2017-04-17  141.83  65.48  32.65\n",
       "2017-04-18  141.20  65.39  32.95\n",
       "2017-04-19  140.68  65.04  33.00\n",
       "2017-04-20  142.44  65.50  33.05\n",
       "2017-04-21  142.27  66.40  32.95\n",
       "2017-04-24  143.64  67.53  33.30\n",
       "2017-04-25  144.53  67.92  33.50\n",
       "2017-04-26  143.68  67.83  35.00\n",
       "2017-04-27  143.79  68.27  35.05\n",
       "2017-04-28  143.65  68.46  34.45\n",
       "2017-05-01  146.58  69.41  34.30\n",
       "2017-05-02  147.51  69.30  34.10\n",
       "2017-05-03  147.06  69.08  32.35\n",
       "2017-05-04  146.53  68.81  32.35\n",
       "2017-05-05  148.96  69.00  31.35\n",
       "2017-05-08  153.01  68.94  31.40\n",
       "2017-05-09  153.99  69.04  31.75\n",
       "2017-05-10  153.26  69.31  31.70\n",
       "2017-05-11  153.95  68.46  29.38\n",
       "2017-05-12  156.10  68.38  29.45\n",
       "2017-05-15  155.70  68.43  29.25\n",
       "2017-05-16  155.47  69.41  29.55\n",
       "2017-05-17  150.25  67.48  28.70\n",
       "2017-05-18  152.54  67.71  28.30\n",
       "2017-05-19  153.06  67.69  28.65\n",
       "2017-05-22  153.99  68.45  29.20\n",
       "2017-05-23  153.80  68.68  29.10\n",
       "2017-05-24  153.34  68.77  29.40\n",
       "2017-05-25  153.87  69.62  29.25\n",
       "\n",
       "[4539 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_close.head(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the Data\n",
    "\n",
    "Our dataset is now complete and free of missing values. We can see a summary of the values in each of the instrument by calling the `describe()` method of a Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>SP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4150.000000</td>\n",
       "      <td>4150.000000</td>\n",
       "      <td>3392.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.580749</td>\n",
       "      <td>32.358166</td>\n",
       "      <td>22.34235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.403515</td>\n",
       "      <td>10.556675</td>\n",
       "      <td>6.81715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.940000</td>\n",
       "      <td>15.150000</td>\n",
       "      <td>11.98000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.090000</td>\n",
       "      <td>25.960000</td>\n",
       "      <td>17.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.715000</td>\n",
       "      <td>28.280000</td>\n",
       "      <td>21.17000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>77.620000</td>\n",
       "      <td>34.277500</td>\n",
       "      <td>24.96000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>156.100000</td>\n",
       "      <td>69.960000</td>\n",
       "      <td>49.95000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AAPL         MSFT          SP\n",
       "count  4150.000000  4150.000000  3392.00000\n",
       "mean     43.580749    32.358166    22.34235\n",
       "std      42.403515    10.556675     6.81715\n",
       "min       0.940000    15.150000    11.98000\n",
       "25%       6.090000    25.960000    17.20000\n",
       "50%      25.715000    28.280000    21.17000\n",
       "75%      77.620000    34.277500    24.96000\n",
       "max     156.100000    69.960000    49.95000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_close.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we would like to plot the **MSFT time-series**. We would also like to see how the stock behaves compared to a short and longer term moving average of its price. A simple moving average of the original time-series is calculated by taking for each date the average of the last *W* prices (including the price on the date of interest). pandas has `rolling()`, a built in function for Series which returns a **rolling object** for a user-defined window, e.g. 20 days. Once a rolling object has been obtained, a number of functions can be applied on it, such as `sum()`, `std()` (to calculate the standard deviation of the values in the window) or `mean()`. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13cef70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the MSFT time series. This now returns a Pandas Series object indexed by date.\n",
    "msft = adj_close.ix[:, 'MSFT']\n",
    "\n",
    "# Calculate the 20 and 100 days moving averages of the closing prices\n",
    "short_rolling_msft = msft.rolling(window=20).mean()\n",
    "long_rolling_msft = msft.rolling(window=100).mean()\n",
    "\n",
    "# Plot everything by leveraging the very powerful matplotlib package\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(msft.index, msft, label='MSFT')\n",
    "ax.plot(short_rolling_msft.index, short_rolling_msft, label='20 days rolling')\n",
    "ax.plot(long_rolling_msft.index, long_rolling_msft, label='100 days rolling')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Adjusted closing price ($)')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, finally the stock price history together with the two moving averages plotted:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Time series for MSFT](finance.png \"Time Series Analysis for MSFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
